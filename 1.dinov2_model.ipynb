{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1083d6-1b7d-4afb-9322-c8d856538bb5",
   "metadata": {},
   "source": [
    "# 使用 DINOv2 生成图片 Embedding\n",
    "\n",
    "本节我们来完成三项任务：\n",
    "\n",
    "1. 从 huggingface 下载 DINOv2 模型文件，并完成单张图片的 Embedding 推理\n",
    "2. 开发批量推理代码：首先实现多张图片在 CPU 上的推理。然后更进阶一点，固定 batch_size 参数，在 GPU 上实现分 batch 推理\n",
    "3. 开发 FastAPI 推理服务，输入图片的 base64 编码，输出图片的 Embedding\n",
    "\n",
    "dinov2:\n",
    "- GitHub: [facebookresearch/dinov2](https://github.com/facebookresearch/dinov2)\n",
    "- Hugging Face: [facebook/dinov2-base](https://huggingface.co/facebook/dinov2-base)\n",
    "\n",
    "> **为什么要做图片 Embeddding：**\n",
    "> \n",
    "> 本项目的目标是对图片做无监督聚类，为了让图片数据适于作为聚类算法的输入，需对图片做预处理。\n",
    "> \n",
    "> 这里列出两种预处理方法，进行比较：\n",
    "> \n",
    "> 1. 将图片输入一个降噪自编码器，让自编码器通过最小化重构损失，学习图片的低维表达\n",
    "> 2. 先将图片用预训练图片 Embedding 模型转换成高维 Embedding，再用自编码器转换成低维 Embedding\n",
    "> \n",
    "> 哪一种方法听起来能获得更好的效果呢？\n",
    "> \n",
    "> 我认为是第二种。因为预训练模型已经通过大规模数据学习到高级语义特征和上下文关系，其 Embedding 能更高效地压缩信息，减少噪音干扰。这意味着后续模型的学习难度更低、效率更高。\n",
    "> \n",
    "> 将预训练模型作为特征提取器使用，是一种通用做法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d9eee-f64d-4deb-88bf-158ac15dec52",
   "metadata": {},
   "source": [
    "## 1. 从 huggingface 下载模型文件\n",
    "\n",
    "```bash\n",
    "# 安装 Hugging Face 提供的，用来下载模型的包\n",
    "pip install -U huggingface_hub\n",
    "\n",
    "export HF_ENDPOINT=https://hf-mirror.com\n",
    "huggingface-cli download --resume-download facebook/dinov2-base --local-dir ./model/dinov2-base\n",
    "```\n",
    "\n",
    "## 2. 计算图片 Embedding\n",
    "\n",
    "使用 Meta 团队的 DINOv2 模型获取 768 维图片 Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a032716-0749-4294-b0a4-a7725360c752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:04:54.464297Z",
     "iopub.status.busy": "2025-03-07T20:04:54.464297Z",
     "iopub.status.idle": "2025-03-07T20:04:59.804760Z",
     "shell.execute_reply": "2025-03-07T20:04:59.804245Z",
     "shell.execute_reply.started": "2025-03-07T20:04:54.464297Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "MODEL_PATH = './model/dinov2-base'\n",
    "IMG_PATH = './img'\n",
    "API_URL = 'http://localhost:8210/embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a01fcd-c334-4de9-b17c-014b186d674e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:04:59.805779Z",
     "iopub.status.busy": "2025-03-07T20:04:59.804760Z",
     "iopub.status.idle": "2025-03-07T20:05:00.244288Z",
     "shell.execute_reply": "2025-03-07T20:05:00.243184Z",
     "shell.execute_reply.started": "2025-03-07T20:04:59.805779Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
    "model = AutoModel.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caba11ec-e515-4295-8120-113690f010b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.246205Z",
     "iopub.status.busy": "2025-03-07T20:05:00.245298Z",
     "iopub.status.idle": "2025-03-07T20:05:00.511101Z",
     "shell.execute_reply": "2025-03-07T20:05:00.510583Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.246205Z"
    }
   },
   "outputs": [],
   "source": [
    "image = Image.open(f'{IMG_PATH}/book.jpg')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c36938-41e3-49da-9b0d-cd5300f20215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.512108Z",
     "iopub.status.busy": "2025-03-07T20:05:00.511101Z",
     "iopub.status.idle": "2025-03-07T20:05:00.517348Z",
     "shell.execute_reply": "2025-03-07T20:05:00.517348Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.512108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6843, -0.7391,  0.5536,  ...,  0.7991, -2.7756, -1.5053],\n",
       "         [-0.0223, -2.5828, -0.6256,  ...,  0.0468, -2.4570, -0.9830],\n",
       "         [ 0.0512, -1.5871, -1.0260,  ..., -0.4017, -2.4379, -1.1177],\n",
       "         ...,\n",
       "         [-0.9939, -0.2953,  3.4886,  ...,  1.0758, -0.2287,  0.5143],\n",
       "         [-0.5174, -0.4167,  1.6565,  ...,  1.9487, -1.0684, -0.0174],\n",
       "         [-1.2063, -0.6236, -0.4622,  ...,  0.2101, -2.1345, -0.9429]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6cf19d-b2bc-4bc0-bd43-93a623ae305d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.518351Z",
     "iopub.status.busy": "2025-03-07T20:05:00.517348Z",
     "iopub.status.idle": "2025-03-07T20:05:00.521356Z",
     "shell.execute_reply": "2025-03-07T20:05:00.521356Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.518351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3801cf-bf99-4db7-9d03-ca6dbaece959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.522359Z",
     "iopub.status.busy": "2025-03-07T20:05:00.522359Z",
     "iopub.status.idle": "2025-03-07T20:05:00.525521Z",
     "shell.execute_reply": "2025-03-07T20:05:00.525521Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.522359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8221a-4ec2-41e9-8120-822c1a11f753",
   "metadata": {},
   "source": [
    "## 3. 批量计算图片 Embedding\n",
    "\n",
    "### 3.1 在 CPU 上批量推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5af6db6-c579-4d23-89cb-137d53c5e465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.526525Z",
     "iopub.status.busy": "2025-03-07T20:05:00.526525Z",
     "iopub.status.idle": "2025-03-07T20:05:00.529524Z",
     "shell.execute_reply": "2025-03-07T20:05:00.529524Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.526525Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_path(dir_path):\n",
    "    img_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "    img_list = [os.path.join(dir_path, f) for f in os.listdir(dir_path) \n",
    "            if f.lower().endswith(img_extensions)]  # 直接过滤图片文件\n",
    "    return [os.path.abspath(p) for p in img_list]  # 转换为绝对路径\n",
    "\n",
    "def load_model(device, model_path=\"facebook/dinov2-base\"):\n",
    "    # 加载模型和预处理器\n",
    "    processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "    model = AutoModel.from_pretrained(model_path).to(device)\n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7bd36e4-5c08-41c7-b833-b85583b7d94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.530557Z",
     "iopub.status.busy": "2025-03-07T20:05:00.529524Z",
     "iopub.status.idle": "2025-03-07T20:05:00.533556Z",
     "shell.execute_reply": "2025-03-07T20:05:00.533556Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.530557Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取指定目录下所有图片文件的绝对路径\n",
    "image_paths = get_img_path(dir_path=IMG_PATH)\n",
    "images = [Image.open(path) for path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ac5e0d-227d-43f3-b52f-d3178493b6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.534072Z",
     "iopub.status.busy": "2025-03-07T20:05:00.534072Z",
     "iopub.status.idle": "2025-03-07T20:05:00.781087Z",
     "shell.execute_reply": "2025-03-07T20:05:00.781087Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.534072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(images=images, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d74943b2-eb2b-434f-9683-54db1f87df2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.781605Z",
     "iopub.status.busy": "2025-03-07T20:05:00.781605Z",
     "iopub.status.idle": "2025-03-07T20:05:00.784707Z",
     "shell.execute_reply": "2025-03-07T20:05:00.784707Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.781605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_values'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f1210-38cd-400c-ab1c-0e33ece85062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T08:10:33.968159Z",
     "iopub.status.busy": "2025-03-07T08:10:33.967220Z",
     "iopub.status.idle": "2025-03-07T08:10:33.972645Z",
     "shell.execute_reply": "2025-03-07T08:10:33.971503Z",
     "shell.execute_reply.started": "2025-03-07T08:10:33.968123Z"
    }
   },
   "source": [
    "### 3.2 在 GPU 上批量推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682f3210-0469-4b96-bc55-76deaf5e7d9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.784707Z",
     "iopub.status.busy": "2025-03-07T20:05:00.784707Z",
     "iopub.status.idle": "2025-03-07T20:05:00.790660Z",
     "shell.execute_reply": "2025-03-07T20:05:00.790660Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.784707Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, processor):\n",
    "        self.image_paths = image_paths\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        return self.processor(images=image, return_tensors=\"pt\")['pixel_values'][0]\n",
    "\n",
    "def batch_inference(dataloader, model, device):\n",
    "    embeddings = []\n",
    "    device = torch.device(device)\n",
    "    for pixel_values in dataloader:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        with torch.autocast(device_type=device.type), torch.no_grad():\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu())\n",
    "\n",
    "        del pixel_values, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef8990f6-a2ca-44ae-880d-fc1fc94bed09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:00.791672Z",
     "iopub.status.busy": "2025-03-07T20:05:00.791672Z",
     "iopub.status.idle": "2025-03-07T20:05:01.016672Z",
     "shell.execute_reply": "2025-03-07T20:05:01.016672Z",
     "shell.execute_reply.started": "2025-03-07T20:05:00.791672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 获取设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载模型\n",
    "model, processor = load_model(device=device, model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f334aade-f4f1-4ced-beec-77d13512afc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:01.017686Z",
     "iopub.status.busy": "2025-03-07T20:05:01.017686Z",
     "iopub.status.idle": "2025-03-07T20:05:01.021071Z",
     "shell.execute_reply": "2025-03-07T20:05:01.021071Z",
     "shell.execute_reply.started": "2025-03-07T20:05:01.017686Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取指定目录下所有图片文件的绝对路径\n",
    "image_paths = get_img_path(dir_path=IMG_PATH)\n",
    "# images = [Image.open(path) for path in image_paths]\n",
    "\n",
    "# 加载数据\n",
    "dataset = ImageDataset(image_paths, processor)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27dadf78-63e8-4dda-ba58-6d6da5717a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:01.022090Z",
     "iopub.status.busy": "2025-03-07T20:05:01.022090Z",
     "iopub.status.idle": "2025-03-07T20:05:01.303121Z",
     "shell.execute_reply": "2025-03-07T20:05:01.303121Z",
     "shell.execute_reply.started": "2025-03-07T20:05:01.022090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = batch_inference(dataloader, model, device=device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a28971b-3ad0-4fb1-aa82-5a90d538d4cf",
   "metadata": {},
   "source": [
    "## 4. 批量推理服务化 \n",
    "\n",
    "### 4.1 启动服务端\n",
    "\n",
    "可以用 FastAPI 将 GPU 批量推理功能做成一个 API 服务。该服务接收一个编码了 N 张图片的 base64 字符串列表，返回一个 N 长的图片 Embedding 列表。 \n",
    "\n",
    "我写了服务端和客户端的代码，放在项目的 `./server` 路径下：\n",
    "\n",
    "- `dinov2_server.py`: DINOv2 Embedding 服务端\n",
    "- `dinov2_client.py`: DINOv2 Embedding 客户端\n",
    "\n",
    "打开命令行，启动 API 服务：\n",
    "\n",
    "```bash\n",
    "cd server\n",
    "python dinov2_server.py\n",
    "```\n",
    "\n",
    "如果启动成功，命令行会输出如下提示信息：\n",
    "\n",
    "```\n",
    "INFO:     Started server process [22220]\n",
    "INFO:     Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "INFO:     Uvicorn running on http://0.0.0.0:8210 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "### 4.2 运行客户端\n",
    "\n",
    "客户端支持多线程分 batch 调用，我们运行客户端，获取一组图片的 Embedding.\n",
    "\n",
    "> 注：服务端默认对返回的 Embedding 进行归一化，可通过可选参数 `normalize` 进行调节，详见代码 `./server/dinov2_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f8d7178-8711-40e4-ad79-f5bf972e1a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:01.304125Z",
     "iopub.status.busy": "2025-03-07T20:05:01.304125Z",
     "iopub.status.idle": "2025-03-07T20:05:01.307657Z",
     "shell.execute_reply": "2025-03-07T20:05:01.307138Z",
     "shell.execute_reply.started": "2025-03-07T20:05:01.304125Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "def client(base64_images):\n",
    "    response = requests.post(\n",
    "        API_URL,\n",
    "        json={\"base64_images\": base64_images},\n",
    "        timeout=30\n",
    "    )\n",
    "    response.raise_for_status()  # 触发 HTTP 错误状态异常\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04254e8-389c-4722-90f0-41f6b26fd721",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:01.307657Z",
     "iopub.status.busy": "2025-03-07T20:05:01.307657Z",
     "iopub.status.idle": "2025-03-07T20:05:03.431918Z",
     "shell.execute_reply": "2025-03-07T20:05:03.431918Z",
     "shell.execute_reply.started": "2025-03-07T20:05:01.307657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = [\n",
    "    './img/cat.jpg',\n",
    "    './img/book.jpg'\n",
    "]\n",
    "base64_images = [image_to_base64(p) for p in image_paths]\n",
    "result = client(base64_images)\n",
    "np.array(result['embeddings']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f4f0e03-35a2-4fcc-9ae3-2e377954f2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-07T20:05:03.432922Z",
     "iopub.status.busy": "2025-03-07T20:05:03.432922Z",
     "iopub.status.idle": "2025-03-07T20:05:03.435065Z",
     "shell.execute_reply": "2025-03-07T20:05:03.435065Z",
     "shell.execute_reply.started": "2025-03-07T20:05:03.432922Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73d3a0-adb3-477e-b426-27742de40ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
