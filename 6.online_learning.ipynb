{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce7b33e-299a-4775-b66f-991104aca57f",
   "metadata": {},
   "source": [
    "# 探索：在线学习\n",
    "\n",
    "我希望当新一批 embeddings 进入时，只进行少量的训练。既让模型适应新数据，又尽量不使原来的 embedding - label 映射发生偏移。\n",
    "\n",
    "我的计划是：\n",
    "\n",
    "1. 先训练一次 DEC 模型\n",
    "2. 再将原本一半样本丢弃，加入与丢弃数量相同的新样本\n",
    "\n",
    "观察模型在新数据集上准确率是否有改善，以及聚类中心的变动是否平缓。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d146c5b-2e2d-4cb2-b4b3-20a21bf16032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:37:06.441788Z",
     "iopub.status.busy": "2025-03-09T22:37:06.441788Z",
     "iopub.status.idle": "2025-03-09T22:37:10.128668Z",
     "shell.execute_reply": "2025-03-09T22:37:10.126651Z",
     "shell.execute_reply.started": "2025-03-09T22:37:06.441788Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import dec\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020f4b71-8556-475a-9125-36b653d5209f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:37:10.134215Z",
     "iopub.status.busy": "2025-03-09T22:37:10.131978Z",
     "iopub.status.idle": "2025-03-09T22:37:10.145411Z",
     "shell.execute_reply": "2025-03-09T22:37:10.143397Z",
     "shell.execute_reply.started": "2025-03-09T22:37:10.134215Z"
    }
   },
   "outputs": [],
   "source": [
    "# 参数配置\n",
    "TRAIN_CSV_PATH = './data/train_embed_label.csv'\n",
    "TEST_CSV_PATH = './data/test_embed_label.csv'\n",
    "\n",
    "# 模型超参数配置\n",
    "config = {\n",
    "    \"dims\": [768, 256, 32],\n",
    "    \"n_clusters\": 100,\n",
    "    \"pretrain_epochs\": 50,\n",
    "    \"soft_dist_epochs\": 100,\n",
    "    \"update_interval\": 10,\n",
    "    \"batch_size\": 256,\n",
    "    \"tol\": 0.001,\n",
    "    \"alpha\": 1.0,\n",
    "    \"save_dir\": \"./model\",\n",
    "    \"args_model_file\": \"dec_args.pth\",\n",
    "    \"full_model_file\": \"dec_full.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f5799-f7f3-4cea-b1fb-98fb3944074f",
   "metadata": {},
   "source": [
    "## 1. 初次训练 DEC 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4eb380f-3c5c-4dc1-a30c-11e636f1762c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:37:10.148409Z",
     "iopub.status.busy": "2025-03-09T22:37:10.148409Z",
     "iopub.status.idle": "2025-03-09T22:40:19.177748Z",
     "shell.execute_reply": "2025-03-09T22:40:19.173487Z",
     "shell.execute_reply.started": "2025-03-09T22:37:10.148409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Pretrain Epoch 10/50, Loss: 0.0009\n",
      "Pretrain Epoch 20/50, Loss: 0.0008\n",
      "Pretrain Epoch 30/50, Loss: 0.0007\n",
      "Pretrain Epoch 40/50, Loss: 0.0007\n",
      "Pretrain Epoch 50/50, Loss: 0.0007\n",
      "init_acc: 0.696\n",
      "===== best_acc: 0.6958 =====\n",
      "===== best_acc: 0.6959 =====\n",
      "DEC Train Epoch 10/100, Loss: 0.0057\n",
      "DEC Train Epoch 20/100, Loss: 0.0065\n",
      "DEC Train Epoch 30/100, Loss: 0.0074\n",
      "DEC Train Epoch 40/100, Loss: 0.0085\n",
      "DEC Train Epoch 50/100, Loss: 0.0098\n",
      "DEC Train Epoch 60/100, Loss: 0.0112\n",
      "DEC Train Epoch 70/100, Loss: 0.0128\n",
      "DEC Train Epoch 80/100, Loss: 0.0147\n",
      "DEC Train Epoch 90/100, Loss: 0.0167\n",
      "DEC Train Epoch 100/100, Loss: 0.0189\n",
      "\n",
      "Final Clustering Results:\n",
      "ACC: 0.6959\n",
      "NMI: 0.8014\n",
      "ARI: 0.5668\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 数据准备\n",
    "X, y_true = dec.load_embed_data(TRAIN_CSV_PATH)\n",
    "dataset = TensorDataset(torch.arange(len(X)), torch.from_numpy(X.astype(np.float32)))\n",
    "pretrain_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "# ======= 阶段一：训练降噪自编码器 =======\n",
    "# 实例化编码器\n",
    "auto_encoder = dec.Autoencoder(config[\"dims\"]).to(device)\n",
    "\n",
    "# 执行编码器预训练代码\n",
    "auto_encoder = dec.pretrain(autoencoder=auto_encoder,\n",
    "                            data_loader=pretrain_loader,\n",
    "                            epochs=50,\n",
    "                            device=device,\n",
    "                            interval=config[\"update_interval\"])\n",
    "\n",
    "# ======= 阶段二：初始化聚类中心 =======\n",
    "full_loader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "kmeans, y_pred, init_acc = dec.init_cluster_centers(encoder=auto_encoder.encoder,\n",
    "                                                    data_loader=full_loader,\n",
    "                                                    n_clusters=config[\"n_clusters\"],\n",
    "                                                    device=device,\n",
    "                                                    y_true=y_true)\n",
    "print(f'init_acc: {init_acc}')\n",
    "\n",
    "# 代表聚类中心的特征向量\n",
    "cluster_centers = torch.tensor(kmeans.cluster_centers_,\n",
    "                               dtype=torch.float,\n",
    "                               requires_grad=True,\n",
    "                               device=device)\n",
    "\n",
    "# ======= 阶段三：训练 DEC =======\n",
    "# 实例化 DEC\n",
    "dec_model = dec.DEC(\n",
    "    cluster_number=config[\"n_clusters\"],  # 预设的聚类数\n",
    "    hidden_dimension=config[\"dims\"][-1],  # 编码器输出维度\n",
    "    encoder=auto_encoder.encoder,\n",
    "    alpha=config[\"alpha\"],\n",
    "    cluster_centers=cluster_centers\n",
    ")\n",
    "data_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "dec_model, dec_acc = dec.train_dec(model=dec_model,\n",
    "                                   data_loader=data_loader,\n",
    "                                   epochs=config[\"soft_dist_epochs\"],\n",
    "                                   device=device,\n",
    "                                   X=X,\n",
    "                                   y_true=y_true,\n",
    "                                   interval=config[\"update_interval\"])\n",
    "\n",
    "# 保存最优模型\n",
    "dec.save_full_model(dec_model, config)\n",
    "dec.save_args_model(dec_model, config)\n",
    "\n",
    "# 计算指标\n",
    "y_pred = dec.infer_embeddings(dec_model, X, device=device)\n",
    "if y_true is not None:\n",
    "    print(\"\\nFinal Clustering Results:\")\n",
    "    print(f\"ACC: {dec.acc(y_true, y_pred):.4f}\")\n",
    "    print(f\"NMI: {dec.nmi(y_true, y_pred):.4f}\")\n",
    "    print(f\"ARI: {dec.ari(y_true, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bb0291-a900-44d7-9d7e-ff9d7527a164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T21:06:15.225754Z",
     "iopub.status.busy": "2025-03-09T21:06:15.224755Z",
     "iopub.status.idle": "2025-03-09T21:06:15.235750Z",
     "shell.execute_reply": "2025-03-09T21:06:15.233743Z",
     "shell.execute_reply.started": "2025-03-09T21:06:15.225754Z"
    }
   },
   "source": [
    "## 2. 生成新样本\n",
    "\n",
    "丢弃原来一半的数据，加入新数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6974c734-f999-4cc8-b3d5-364727109d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:40:19.179669Z",
     "iopub.status.busy": "2025-03-09T22:40:19.179669Z",
     "iopub.status.idle": "2025-03-09T22:40:19.208310Z",
     "shell.execute_reply": "2025-03-09T22:40:19.207147Z",
     "shell.execute_reply.started": "2025-03-09T22:40:19.179669Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomly_discard_half(X, y, seed=None):\n",
    "    \"\"\"随机丢弃一半的 X 和 y\"\"\"\n",
    "    assert len(X) == len(y)\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # 转换为 numpy 数组\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # 生成一个随机排列的索引序列\n",
    "    num_samples = len(X)\n",
    "    random_indices = np.random.permutation(num_samples)\n",
    "\n",
    "    # 选择前一半的索引\n",
    "    half_indices = random_indices[:num_samples // 2]\n",
    "\n",
    "    # 根据索引选择数据\n",
    "    return X[half_indices], y[half_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57440381-be9a-491f-a3cf-6ff58fc671cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:40:19.211480Z",
     "iopub.status.busy": "2025-03-09T22:40:19.211480Z",
     "iopub.status.idle": "2025-03-09T22:41:30.044460Z",
     "shell.execute_reply": "2025-03-09T22:41:30.044460Z",
     "shell.execute_reply.started": "2025-03-09T22:40:19.211480Z"
    }
   },
   "outputs": [],
   "source": [
    "# 旧数据丢弃一半\n",
    "half_X, half_y_true = randomly_discard_half(X, y_true, seed=42)\n",
    "\n",
    "# 新数据也丢弃一半\n",
    "test_X, test_y_true = dec.load_embed_data(TEST_CSV_PATH)\n",
    "half_test_X, half_test_y_true = randomly_discard_half(test_X, test_y_true, seed=37)\n",
    "\n",
    "# 新旧数据合并\n",
    "new_X = np.concatenate((half_X, half_test_X))\n",
    "new_y_true = np.concatenate((half_y_true, half_test_y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95dc585b-708f-4e67-83d6-c9cd729d0d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:30.054035Z",
     "iopub.status.busy": "2025-03-09T22:41:30.050579Z",
     "iopub.status.idle": "2025-03-09T22:41:30.073038Z",
     "shell.execute_reply": "2025-03-09T22:41:30.073038Z",
     "shell.execute_reply.started": "2025-03-09T22:41:30.054035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 768), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.shape, new_y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e15df4-217a-4234-83aa-f003a004bc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:30.075779Z",
     "iopub.status.busy": "2025-03-09T22:41:30.075779Z",
     "iopub.status.idle": "2025-03-09T22:41:30.109087Z",
     "shell.execute_reply": "2025-03-09T22:41:30.106628Z",
     "shell.execute_reply.started": "2025-03-09T22:41:30.075779Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "new_dataset = TensorDataset(torch.arange(len(new_X)), torch.from_numpy(new_X.astype(np.float32)))\n",
    "new_data_loader = DataLoader(new_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1bf9a-e3b2-4143-b237-393cc44a6452",
   "metadata": {},
   "source": [
    "## 3. 增量训练\n",
    "\n",
    "使用新数据集对原模型做增量训练。在训练前，先评估一下原模型在新数据集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a9f3f4-3d69-4b58-bdc1-77ba6e88da9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:30.109087Z",
     "iopub.status.busy": "2025-03-09T22:41:30.109087Z",
     "iopub.status.idle": "2025-03-09T22:41:30.115717Z",
     "shell.execute_reply": "2025-03-09T22:41:30.115717Z",
     "shell.execute_reply.started": "2025-03-09T22:41:30.109087Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存原模型重要参数\n",
    "\n",
    "# 原模型的聚类中心\n",
    "old_cluster_centers = dec_model.assignment.cluster_centers\n",
    "\n",
    "# 原模型的 encoder\n",
    "old_encoder = dec_model.encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c5c8a-1fa9-4c94-af06-760ffcc427bb",
   "metadata": {},
   "source": [
    "1）原模型在新数据集上的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ddc547-d7ad-4d92-8290-207efb8cc0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:30.119393Z",
     "iopub.status.busy": "2025-03-09T22:41:30.115717Z",
     "iopub.status.idle": "2025-03-09T22:41:31.068295Z",
     "shell.execute_reply": "2025-03-09T22:41:31.068295Z",
     "shell.execute_reply.started": "2025-03-09T22:41:30.119393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Clustering Results:\n",
      "ACC: 0.6888\n",
      "NMI: 0.7935\n",
      "ARI: 0.5515\n"
     ]
    }
   ],
   "source": [
    "new_y_pred = dec.infer_embeddings(dec_model, new_X, device=device)\n",
    "print(\"Final Clustering Results:\")\n",
    "print(f\"ACC: {dec.acc(new_y_true, new_y_pred):.4f}\")\n",
    "print(f\"NMI: {dec.nmi(new_y_true, new_y_pred):.4f}\")\n",
    "print(f\"ARI: {dec.ari(new_y_true, new_y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917f7128-7388-467b-b58c-1f7b1603085b",
   "metadata": {},
   "source": [
    "接下来开始训练增量模型。\n",
    "\n",
    "2）思路一：移动聚类中心\n",
    "\n",
    "1. 计算新聚类中心\n",
    "2. 用 linear_sum_assignment 函数匹配新老聚类中心\n",
    "3. 在老聚类中心的基础上，向新中心做一点平移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6259c5-e789-450c-9d3b-d834e9ecfee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:31.070478Z",
     "iopub.status.busy": "2025-03-09T22:41:31.070478Z",
     "iopub.status.idle": "2025-03-09T22:41:31.085928Z",
     "shell.execute_reply": "2025-03-09T22:41:31.083272Z",
     "shell.execute_reply.started": "2025-03-09T22:41:31.070478Z"
    }
   },
   "outputs": [],
   "source": [
    "def match_and_translate_centers(old_centers, new_centers, translation_ratio=0.1):\n",
    "    \"\"\"\n",
    "    匹配新老聚类中心并进行平移\n",
    "    :param old_centers: 老的聚类中心，形状为 (n_clusters, n_features)\n",
    "    :param new_centers: 新的聚类中心，形状为 (n_clusters, n_features)\n",
    "    :param translation_ratio: 平移比例，取值范围为 [0, 1]\n",
    "    :return: 平移后的聚类中心 标签映射字典\n",
    "    \"\"\"\n",
    "    # 计算新老中心之间的距离矩阵\n",
    "    distance_matrix = np.linalg.norm(old_centers[:, np.newaxis] - new_centers, axis=-1)\n",
    "    # 使用 linear_sum_assignment 匹配新老中心\n",
    "    row_indices, col_indices = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "    # 构建标签映射\n",
    "    mapping = {old_label: new_label for old_label, new_label in zip(row_indices, col_indices)}\n",
    "\n",
    "    # 进行平移\n",
    "    translated_centers = old_centers.copy()\n",
    "    for old_idx, new_idx in zip(row_indices, col_indices):\n",
    "        translated_centers[old_idx] += translation_ratio * (new_centers[new_idx] - old_centers[old_idx])\n",
    "\n",
    "    return translated_centers, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48bfd2bc-9756-4760-833c-d3db725c1de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:31.088334Z",
     "iopub.status.busy": "2025-03-09T22:41:31.087265Z",
     "iopub.status.idle": "2025-03-09T22:41:43.110132Z",
     "shell.execute_reply": "2025-03-09T22:41:43.110132Z",
     "shell.execute_reply.started": "2025-03-09T22:41:31.088334Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算新的聚类中心\n",
    "nc_kmeans, nc_y_pred, nc_init_acc = dec.init_cluster_centers(encoder=old_encoder,\n",
    "                                                             data_loader=new_data_loader,\n",
    "                                                             n_clusters=config[\"n_clusters\"],\n",
    "                                                             device=device,\n",
    "                                                             y_true=new_y_true)\n",
    "nc_centers = nc_kmeans.cluster_centers_\n",
    "\n",
    "# 匹配并平移聚类中心\n",
    "translated_centers, mapping = match_and_translate_centers(old_centers=old_cluster_centers.cpu().detach().numpy(),\n",
    "                                                          new_centers=nc_centers,\n",
    "                                                          translation_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d54373-a484-4262-82a9-82e55b5915d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:43.114763Z",
     "iopub.status.busy": "2025-03-09T22:41:43.114249Z",
     "iopub.status.idle": "2025-03-09T22:41:43.122327Z",
     "shell.execute_reply": "2025-03-09T22:41:43.121623Z",
     "shell.execute_reply.started": "2025-03-09T22:41:43.114763Z"
    }
   },
   "outputs": [],
   "source": [
    "# mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35b550b5-a74d-47d7-b4ec-a80d317d7a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:43.123503Z",
     "iopub.status.busy": "2025-03-09T22:41:43.123503Z",
     "iopub.status.idle": "2025-03-09T22:41:43.152751Z",
     "shell.execute_reply": "2025-03-09T22:41:43.152751Z",
     "shell.execute_reply.started": "2025-03-09T22:41:43.123503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_distance: 0.0069\n",
      "max_distance: 0.0636\n"
     ]
    }
   ],
   "source": [
    "# 评估聚类中心移动距离\n",
    "old_vectors = dec_model.assignment.cluster_centers.cpu().detach()\n",
    "new_vectors = torch.Tensor(translated_centers)\n",
    "\n",
    "# 计算每对向量的欧氏距离\n",
    "euclidean_distances = torch.norm(old_vectors - new_vectors, dim=1)\n",
    "\n",
    "# 计算欧氏距离的均值和最大值\n",
    "mean_distance = torch.mean(euclidean_distances)\n",
    "max_distance = torch.max(euclidean_distances)\n",
    "\n",
    "# print(f\"euclidean_distances: {euclidean_distances}\")\n",
    "print(f\"mean_distance: {mean_distance:.4f}\")\n",
    "print(f\"max_distance: {max_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "010d48dd-4656-4316-996a-522a701b8b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:43.155268Z",
     "iopub.status.busy": "2025-03-09T22:41:43.154756Z",
     "iopub.status.idle": "2025-03-09T22:41:43.170990Z",
     "shell.execute_reply": "2025-03-09T22:41:43.170990Z",
     "shell.execute_reply.started": "2025-03-09T22:41:43.155268Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加入 L2 正则化，以及更严格的梯度裁剪\n",
    "def train_dec(model, data_loader, epochs, device, X, y_true=None, interval=10):\n",
    "    \"\"\"通过目标分布引导聚类优化\"\"\"\n",
    "\n",
    "    # 记录最优模型\n",
    "    best_model, best_acc = None, None\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.encoder.parameters(), 'lr': 1e-6},\n",
    "        {'params': model.assignment.parameters(), 'lr': 1e-5}\n",
    "    ])\n",
    "\n",
    "    criterion = F.kl_div\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for idx, x in data_loader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            target = dec.target_distribution(output).detach()\n",
    "\n",
    "            # 加入 L2 正则化\n",
    "            lambda_reg = 1e-4  # 正则化系数\n",
    "            loss = criterion(output.log(), target, reduction='batchmean') + \\\n",
    "                lambda_reg * model.assignment.cluster_centers.norm(2)\n",
    "            loss.backward()\n",
    "\n",
    "            # 更严格的梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                           max_norm=0.5,\n",
    "                                           norm_type=2)\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        if (epoch + 1) % interval == 0:\n",
    "            print(f\"DEC Train Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if y_true is not None:\n",
    "            # 计算准确率\n",
    "            with torch.no_grad():\n",
    "                input = torch.from_numpy(X).float().to(device)\n",
    "                y_pred = model(input).argmax(1).cpu().numpy()\n",
    "            current_acc = dec.acc(y_true, y_pred)\n",
    "\n",
    "            # 更新最优模型\n",
    "            if best_acc is None or current_acc > best_acc:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_acc = current_acc\n",
    "                print(f'===== best_acc: {best_acc:.4f} =====')\n",
    "\n",
    "    return model if best_model is None else best_model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc10190-dbe9-46dd-8923-2756a11329fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:43.173874Z",
     "iopub.status.busy": "2025-03-09T22:41:43.173874Z",
     "iopub.status.idle": "2025-03-09T22:41:48.844642Z",
     "shell.execute_reply": "2025-03-09T22:41:48.844642Z",
     "shell.execute_reply.started": "2025-03-09T22:41:43.173874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEC Train Epoch 1/10, Loss: 0.0058\n",
      "===== best_acc: 0.6905 =====\n",
      "DEC Train Epoch 2/10, Loss: 0.0059\n",
      "DEC Train Epoch 3/10, Loss: 0.0059\n",
      "DEC Train Epoch 4/10, Loss: 0.0060\n",
      "DEC Train Epoch 5/10, Loss: 0.0061\n",
      "DEC Train Epoch 6/10, Loss: 0.0062\n",
      "DEC Train Epoch 7/10, Loss: 0.0062\n",
      "DEC Train Epoch 8/10, Loss: 0.0063\n",
      "DEC Train Epoch 9/10, Loss: 0.0064\n",
      "DEC Train Epoch 10/10, Loss: 0.0065\n"
     ]
    }
   ],
   "source": [
    "# 新的超参数\n",
    "new_soft_dist_epochs = 10\n",
    "new_update_interval = 1\n",
    "\n",
    "# 重新实例化一个 DEC\n",
    "new_dec_model = dec.DEC(\n",
    "    cluster_number=config[\"n_clusters\"],  # 预设的聚类数\n",
    "    hidden_dimension=config[\"dims\"][-1],  # 编码器输出维度\n",
    "    encoder=old_encoder,\n",
    "    alpha=config[\"alpha\"],\n",
    "    cluster_centers=torch.Tensor(translated_centers).to(device)  # 替换聚类中心\n",
    ")\n",
    "new_dec_model, new_dec_acc = train_dec(model=new_dec_model,\n",
    "                                       data_loader=new_data_loader,\n",
    "                                       epochs=new_soft_dist_epochs,\n",
    "                                       device=device,\n",
    "                                       X=new_X,\n",
    "                                       y_true=new_y_true,\n",
    "                                       interval=new_update_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e3d22d7-c4aa-4f92-997f-0b033ca66747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:48.846482Z",
     "iopub.status.busy": "2025-03-09T22:41:48.846482Z",
     "iopub.status.idle": "2025-03-09T22:41:49.075537Z",
     "shell.execute_reply": "2025-03-09T22:41:49.075537Z",
     "shell.execute_reply.started": "2025-03-09T22:41:48.846482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Clustering Results:\n",
      "ACC: 0.6905\n",
      "NMI: 0.7945\n",
      "ARI: 0.5543\n"
     ]
    }
   ],
   "source": [
    "# 计算指标\n",
    "nn_y_pred = dec.infer_embeddings(new_dec_model, new_X, device=device)\n",
    "print(\"Final Clustering Results:\")\n",
    "print(f\"ACC: {dec.acc(new_y_true, nn_y_pred):.4f}\")\n",
    "print(f\"NMI: {dec.nmi(new_y_true, nn_y_pred):.4f}\")\n",
    "print(f\"ARI: {dec.ari(new_y_true, nn_y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8f4b51-dc22-4aee-8408-a44372ab513a",
   "metadata": {},
   "source": [
    "3）思路二：重新拟合目标分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe75572-7934-4730-b6d3-7a33784f7ecc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:49.075537Z",
     "iopub.status.busy": "2025-03-09T22:41:49.075537Z",
     "iopub.status.idle": "2025-03-09T22:41:49.089159Z",
     "shell.execute_reply": "2025-03-09T22:41:49.087616Z",
     "shell.execute_reply.started": "2025-03-09T22:41:49.075537Z"
    }
   },
   "outputs": [],
   "source": [
    "# dir(dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fc60b9a-bd12-4f4f-b692-5a781ce2ec94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:49.091932Z",
     "iopub.status.busy": "2025-03-09T22:41:49.091932Z",
     "iopub.status.idle": "2025-03-09T22:41:49.124110Z",
     "shell.execute_reply": "2025-03-09T22:41:49.122099Z",
     "shell.execute_reply.started": "2025-03-09T22:41:49.091932Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加入 L2 正则化，以及更严格的梯度裁剪\n",
    "def train_dec(model, data_loader, epochs, device, X, y_true=None, interval=10):\n",
    "    \"\"\"通过目标分布引导聚类优化\"\"\"\n",
    "\n",
    "    # 记录最优模型\n",
    "    best_model, best_acc = None, None\n",
    "\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.encoder.parameters(), 'lr': 1e-6},\n",
    "        {'params': model.assignment.parameters(), 'lr': 1e-5}\n",
    "    ])\n",
    "\n",
    "    criterion = F.kl_div\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for idx, x in data_loader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            target = dec.target_distribution(output).detach()\n",
    "\n",
    "            # 加入 L2 正则化\n",
    "            lambda_reg = 1e-4  # 正则化系数\n",
    "            loss = criterion(output.log(), target, reduction='batchmean') + \\\n",
    "                lambda_reg * model.assignment.cluster_centers.norm(2)\n",
    "            loss.backward()\n",
    "\n",
    "            # 更严格的梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                           max_norm=0.5,\n",
    "                                           norm_type=2)\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        if (epoch + 1) % interval == 0:\n",
    "            print(f\"DEC Train Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        if y_true is not None:\n",
    "            # 计算准确率\n",
    "            with torch.no_grad():\n",
    "                input = torch.from_numpy(X).float().to(device)\n",
    "                y_pred = model(input).argmax(1).cpu().numpy()\n",
    "            current_acc = dec.acc(y_true, y_pred)\n",
    "\n",
    "            # 更新最优模型\n",
    "            if best_acc is None or current_acc > best_acc:\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_acc = current_acc\n",
    "                print(f'===== best_acc: {best_acc:.4f} =====')\n",
    "\n",
    "    return model if best_model is None else best_model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a76b1c-38b5-4d40-9042-0bb6630a9b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:49.127636Z",
     "iopub.status.busy": "2025-03-09T22:41:49.124110Z",
     "iopub.status.idle": "2025-03-09T22:41:54.857899Z",
     "shell.execute_reply": "2025-03-09T22:41:54.857899Z",
     "shell.execute_reply.started": "2025-03-09T22:41:49.127636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEC Train Epoch 1/10, Loss: 0.0061\n",
      "===== best_acc: 0.6920 =====\n",
      "DEC Train Epoch 2/10, Loss: 0.0062\n",
      "DEC Train Epoch 3/10, Loss: 0.0063\n",
      "DEC Train Epoch 4/10, Loss: 0.0064\n",
      "DEC Train Epoch 5/10, Loss: 0.0064\n",
      "DEC Train Epoch 6/10, Loss: 0.0065\n",
      "DEC Train Epoch 7/10, Loss: 0.0066\n",
      "DEC Train Epoch 8/10, Loss: 0.0067\n",
      "DEC Train Epoch 9/10, Loss: 0.0067\n",
      "DEC Train Epoch 10/10, Loss: 0.0068\n"
     ]
    }
   ],
   "source": [
    "# 新的超参数\n",
    "new_soft_dist_epochs = 10\n",
    "new_update_interval = 1\n",
    "\n",
    "# 重新实例化一个 DEC\n",
    "new_dec_model = dec.DEC(\n",
    "    cluster_number=config[\"n_clusters\"],  # 预设的聚类数\n",
    "    hidden_dimension=config[\"dims\"][-1],  # 编码器输出维度\n",
    "    encoder=old_encoder,\n",
    "    alpha=config[\"alpha\"],\n",
    "    cluster_centers=old_cluster_centers\n",
    ")\n",
    "new_dec_model, new_dec_acc = train_dec(model=new_dec_model,\n",
    "                                       data_loader=new_data_loader,\n",
    "                                       epochs=new_soft_dist_epochs,\n",
    "                                       device=device,\n",
    "                                       X=new_X,\n",
    "                                       y_true=new_y_true,\n",
    "                                       interval=new_update_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ff59fa5-7c35-44a6-b40c-d364d6b4fdfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T22:41:54.861523Z",
     "iopub.status.busy": "2025-03-09T22:41:54.861523Z",
     "iopub.status.idle": "2025-03-09T22:41:55.042732Z",
     "shell.execute_reply": "2025-03-09T22:41:55.042732Z",
     "shell.execute_reply.started": "2025-03-09T22:41:54.861523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Clustering Results:\n",
      "ACC: 0.6920\n",
      "NMI: 0.7953\n",
      "ARI: 0.5561\n"
     ]
    }
   ],
   "source": [
    "# 计算指标\n",
    "nn_y_pred = dec.infer_embeddings(new_dec_model, new_X, device=device)\n",
    "print(\"Final Clustering Results:\")\n",
    "print(f\"ACC: {dec.acc(new_y_true, nn_y_pred):.4f}\")\n",
    "print(f\"NMI: {dec.nmi(new_y_true, nn_y_pred):.4f}\")\n",
    "print(f\"ARI: {dec.ari(new_y_true, nn_y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684ac34-4c61-4614-b290-f5c7671d445e",
   "metadata": {},
   "source": [
    "EWC的弹性约束？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0989593-277d-413d-a750-298ff3b8fda1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
